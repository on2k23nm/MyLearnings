{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_IMAGES_DIR = Path('/home/onkar/DATASET/carvana-image-masking-challenge/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(42)\n",
    "# height=240, width=448\n",
    "class CaravanaDataset(Dataset):\n",
    "    def __init__(self, root_dir) -> None:\n",
    "        super(CaravanaDataset, self).__init__()\n",
    "        self.all_files = self.create_file_list(root_dir)\n",
    "        \n",
    "    @staticmethod\n",
    "    def create_file_list(root_dir):\n",
    "        images = root_dir/'images'\n",
    "        masks  = root_dir/'masks'\n",
    "        \n",
    "        # print(f'Image file : {images}, Mask file : {images}')\n",
    "        \n",
    "        all_files = []\n",
    "        for img_fl in images.glob('*.npy'):\n",
    "            mask_fl = img_fl.with_stem(img_fl.stem + '_mask').with_suffix('.npy')\n",
    "            \n",
    "            parts = list(mask_fl.parts)\n",
    "            parts[-2] = 'masks'\n",
    "            mask_fl = Path(*parts)\n",
    "            \n",
    "            # print(f'Image file : {img_fl}, Mask file : {mask_fl}')\n",
    "\n",
    "            all_files.append((img_fl, mask_fl))\n",
    "        \n",
    "        random.shuffle(all_files)\n",
    "        \n",
    "        return all_files\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.all_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ## Apply augmentations before returning\n",
    "        \n",
    "        # get the item at index idx\n",
    "        image_path, mask_path = self.all_files[idx]\n",
    "        \n",
    "        image = np.load(image_path).astype(np.float32)\n",
    "        mask = np.load(mask_path).astype(np.float32)\n",
    "        # print(f'image_path : {image_path}, mask_path :{mask_path}')\n",
    "        # image = np.memmap(image_path, dtype=np.float32, mode='r', shape=(480, 896))\n",
    "        # mask = np.memmap(mask_path, dtype=np.float32, mode='r', shape=(480, 896))\n",
    "    \n",
    "        return (torch.from_numpy(image), torch.from_numpy(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for testing purpose only\n",
    "# BATCH_SIZE = 5\n",
    "# NUM_WORKERS = 1\n",
    "# PIN_MEMORY = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING_DATASET = PROCESSED_IMAGES_DIR/'train'\n",
    "# train_ds = CaravanaDataset(TRAINING_DATASET)\n",
    "# # print(len(train_ds))\n",
    "# # print(train_ds[0])\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_ds,\n",
    "#                                             batch_size=BATCH_SIZE,\n",
    "#                                             num_workers=NUM_WORKERS,\n",
    "#                                             shuffle=True)\n",
    "\n",
    "# # Fetch a single batch from the DataLoader\n",
    "# data_iter = iter(train_loader)\n",
    "# image1, mask1 = next(data_iter)\n",
    "# print(f'image.shape : {image1.shape}, mask.shape : {mask1.shape}')\n",
    "# print(f'image.shape : {image1.permute([0, 3, 1, 2]).shape}, mask.shape : {mask1.shape}')\n",
    "# # print(image1, mask1)\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(10, 10))\n",
    "# axes[0].imshow(image1[0].numpy())\n",
    "# axes[1].imshow(mask1[0].numpy())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION_DATASET = PROCESSED_IMAGES_DIR/'val'\n",
    "\n",
    "# valid_ds = CaravanaDataset(VALIDATION_DATASET)\n",
    "\n",
    "# # print(len(valid_ds))\n",
    "# # print(valid_ds[0])\n",
    "\n",
    "# val_loader = torch.utils.data.DataLoader(dataset=valid_ds,\n",
    "#                                             batch_size=BATCH_SIZE,\n",
    "#                                             num_workers=NUM_WORKERS)\n",
    "\n",
    "# # Fetch a single batch from the DataLoader\n",
    "# data_iter = iter(val_loader)\n",
    "# image2, mask2 = next(data_iter)\n",
    "# print(f'image.shape : {image2.shape}, mask.shape : {mask2.shape}')\n",
    "# print(f'image.shape : {image2.permute([0, 3, 1, 2]).shape}, mask.shape : {mask2.shape}')\n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(10, 10))\n",
    "# axes[0].imshow(image2[0].numpy())\n",
    "# axes[1].imshow(mask2[0].numpy())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
