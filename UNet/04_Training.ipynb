{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset.py so that we can load the CaravanaDataset and other things from it.\n",
    "# /home/onkar/MyLearnings/UNet\n",
    "# <-- comment after files are created -->\n",
    "\n",
    "# !jupyter nbconvert --to script 02_Dataset.ipynb --output DataSet\n",
    "# !jupyter nbconvert --to script 03_Model.ipynb --output SegModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from SegModel import UNet\n",
    "\n",
    "from DataSet import PROCESSED_IMAGES_DIR\n",
    "\n",
    "from utils import (\n",
    "    save_checkpoint,\n",
    "    load_checkpoint,\n",
    "    check_accuracy,\n",
    "    save_preds_as_imgs,\n",
    "    create_dataset,\n",
    "    get_dataloader\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 448, 240])\n",
      "torch.Size([1, 1, 448, 240])\n"
     ]
    }
   ],
   "source": [
    "# -- Test Model if working properly --\n",
    "\n",
    "def test():\n",
    "    x = torch.randn((1, 3, 448, 240))\n",
    "    model = UNet(in_channels=3, out_channels=1)\n",
    "    pred = model(x)\n",
    "    print(x.shape)\n",
    "    print(pred.shape)\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 3\n",
    "NUM_WORKERS = 1\n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = True\n",
    "\n",
    "# Other information\n",
    "TRAINING_DATASET_PATH=PROCESSED_IMAGES_DIR/'train'\n",
    "VALIDATION_DATASET_PATH=PROCESSED_IMAGES_DIR/'val'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading Checkpoint\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3a805166cd4b2984ae4e6ae61a4f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 163102813/164183040 with accuracy of 99.342%, Dice score : 95.075\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34fddfc4020420db656ace98151c3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/223 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving Checkpoint\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8baf9b928be4445bb063be1f5706be89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 163286253/164183040 with accuracy of 99.454%, Dice score : 95.233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71c625e9bcf49b8bcfaf3183046cf0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/223 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving Checkpoint\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175eb973c8cb4f3d816bc5d5d12d249e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 163340751/164183040 with accuracy of 99.487%, Dice score : 95.277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b45d6a424a44d6f829d85c039dcbb14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/223 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving Checkpoint\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454ea9e7080042f3b48f86fdb10bf733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 163425317/164183040 with accuracy of 99.538%, Dice score : 95.351\n"
     ]
    }
   ],
   "source": [
    "# Training function will run over one batch and will return the training loss\n",
    "def train_func(loader, model, optimizer, loss_fn, scaler):\n",
    "    # Sometimes, the GPU memory is not properly cleared. You can free the cached memory\n",
    "    # by calling torch.cuda.empty_cache().\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    loop = tqdm(loader)\n",
    "    for batch_idx, (images, targets) in enumerate(loop):\n",
    "        images = images.permute([0, 3, 1, 2]).to(device=DEVICE)\n",
    "        targets  = targets.unsqueeze(1).to(device=DEVICE)\n",
    "        # print(f'images.size : {images.size()}, targets.size : {targets.size()}')\n",
    "        \n",
    "        # Forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            preds = model(images)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # update tqdm loop\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "def main():\n",
    "    # get dataset\n",
    "    training_ds = create_dataset(TRAINING_DATASET_PATH)\n",
    "    validation_ds = create_dataset(VALIDATION_DATASET_PATH)\n",
    "    \n",
    "    # Create a dataloader for loading data in batches\n",
    "    training_loader = get_dataloader(\n",
    "                                dataset=training_ds,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                num_workers=NUM_WORKERS,\n",
    "                                shuffle=True\n",
    "                                )\n",
    "    validation_loader = get_dataloader(\n",
    "                            dataset=validation_ds,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            num_workers=NUM_WORKERS,\n",
    "                            shuffle=False\n",
    "                            )\n",
    "    \n",
    "    # Set a model\n",
    "    model = UNet(in_channels=3, out_channels=1).to(device=DEVICE)\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss() # 2 classes 'Car' or 'Not car', if more than one class use cross entropy loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    if LOAD_MODEL:\n",
    "        load_checkpoint(checkpoint=torch.load('checkpoints/my_checkpoint.pth'), model=model)\n",
    "    \n",
    "    check_accuracy(loader=validation_loader, model=model, device=DEVICE)\n",
    "    \n",
    "    # Start the training     \n",
    "    scaler = GradScaler()\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_func(training_loader, model, optimizer, loss_fn, scaler)\n",
    "        \n",
    "        # -- Save model --\n",
    "        checkpoint = {\n",
    "            \"state_dict\" : model.state_dict(), \n",
    "            \"optimizer\"  : optimizer.state_dict(),\n",
    "        }\n",
    "        \n",
    "        save_checkpoint(checkpoint)\n",
    "            \n",
    "        with torch.no_grad():    \n",
    "            # -- Check accuracy --\n",
    "            check_accuracy(loader=validation_loader, model=model, device=DEVICE)\n",
    "        \n",
    "            # print some examples to folder\n",
    "            save_preds_as_imgs(validation_loader, model=model,save_dir='pred_images', device=DEVICE)\n",
    "      \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
