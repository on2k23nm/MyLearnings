{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 03_Model.ipynb to script\n",
      "[NbConvertApp] Writing 8725 bytes to SegModel.py\n"
     ]
    }
   ],
   "source": [
    "# Create Dataset.py so that we can load the CaravanaDataset and other things from it.\n",
    "\n",
    "# <-- comment after files are created -->\n",
    "\n",
    "# !jupyter nbconvert --to script 02_Dataset.ipynb --output CaravanaDataset\n",
    "# !jupyter nbconvert --to script 03_Model.ipynb --output SegModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from SegModel import UNet\n",
    "\n",
    "from CaravanaDataset import (\n",
    "    val_loader, train_loader, PROCESSED_IMAGES_DIR\n",
    ")\n",
    "\n",
    "from utils import (\n",
    "    save_checkpoint,\n",
    "    load_checkpoint,\n",
    "    check_accuracy,\n",
    "    save_preds_as_imgs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1792, 832])\n",
      "torch.Size([1, 3, 1792, 832])\n"
     ]
    }
   ],
   "source": [
    "# -- Test Model if working properly --\n",
    "\n",
    "def test():\n",
    "    x = torch.randn((1, 3, 1792, 832))\n",
    "    model = UNet(in_channels=3, out_channels=2)\n",
    "    pred = model(x)\n",
    "    print(x.shape)\n",
    "    print(pred.shape)\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 1\n",
    "NUM_WORKERS = 2\n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function will run over one batch and will return the training loss\n",
    "def train_func(loader, model, optimizer, loss_fn, scalar):\n",
    "    loop = tqdm(train_loader)\n",
    "    for batch_idx, (images, targets) in enumerate(loop):\n",
    "        images = images.permute([0, 3, 1, 2]).to(device=DEVICE)\n",
    "        masks  = masks.unsqueeze(1).to(device=DEVICE)\n",
    "        \n",
    "        # Forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            preds = model(images)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        scalar.scale(loss).backward()\n",
    "        scalar.step(optimizer)\n",
    "        scalar.update()\n",
    "        \n",
    "        # update tqdm loop\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "def main():\n",
    "    ## set a model \n",
    "    model = UNet(in_channels=3, out_channels=2).to(device=DEVICE)\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss() # 2 classes 'Car' or 'Not car', if more than one class use cross entropy loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    ## loaders here ..\n",
    "    \n",
    "    scalar = torch.cuda.amp.GradScalar()\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_func(train_loader, model, optimizer, loss_fn, scalar)\n",
    "        \n",
    "        # -- Save model --\n",
    "        checkpoint = {\n",
    "            \"state_dict\" : model.state_dict(), \n",
    "            \"optimizer\"  : optimizer.state_dict(),\n",
    "        }\n",
    "        \n",
    "        save_checkpoint(checkpoint)\n",
    "        \n",
    "        # -- Check accuracy --\n",
    "        check_accuracy(loader=val_loader, model=model, device=DEVICE)\n",
    "        \n",
    "        \n",
    "        # print some examples to folder\n",
    "        save_preds_as_imgs(val_loader, model=model,save_dir='pred_images', device=DEVICE)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
